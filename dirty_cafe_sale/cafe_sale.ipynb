{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17dc294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_2008\\1585058692.py:7: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"dirty_cafe_sales.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training\",\n",
    "  file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be6cb2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>item</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>location</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_2602893</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_4433211</td>\n",
       "      <td>Cake/Juice</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN_6699534</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN_4717867</td>\n",
       "      <td>Cake/Juice</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN_2064365</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id        item  quantity  price_per_unit  total_spent  \\\n",
       "0    TXN_1961373      Coffee       2.0             2.0          4.0   \n",
       "1    TXN_4977031        Cake       4.0             3.0         12.0   \n",
       "2    TXN_4271903      Cookie       4.0             1.0          4.0   \n",
       "3    TXN_7034554       Salad       2.0             5.0         10.0   \n",
       "4    TXN_3160411      Coffee       2.0             2.0          4.0   \n",
       "5    TXN_2602893    Smoothie       5.0             4.0         20.0   \n",
       "6    TXN_4433211  Cake/Juice       3.0             3.0          9.0   \n",
       "7    TXN_6699534    Sandwich       4.0             4.0         16.0   \n",
       "8    TXN_4717867  Cake/Juice       5.0             3.0         15.0   \n",
       "9    TXN_2064365    Sandwich       5.0             4.0         20.0   \n",
       "\n",
       "   payment_method  location transaction_date  \n",
       "0     Credit Card  Takeaway       2023-09-08  \n",
       "1            Cash  In-store       2023-05-16  \n",
       "2     Credit Card  In-store       2023-07-19  \n",
       "3             NaN       NaN       2023-04-27  \n",
       "4  Digital Wallet  In-store       2023-06-11  \n",
       "5     Credit Card       NaN       2023-03-31  \n",
       "6             NaN  Takeaway       2023-10-06  \n",
       "7            Cash       NaN       2023-10-28  \n",
       "8             NaN  Takeaway       2023-07-28  \n",
       "9             NaN  In-store       2023-12-31  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running this to get a glimpse of the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd7ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names.\n",
    "# Remove leading/trailing spaces, replace spaces with underscores, and convert to lowercase.\n",
    "df.columns = df.columns.str.strip().str.replace(' ', '_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c71554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Column: transaction_id\n",
      "Value Counts:\n",
      "transaction_id\n",
      "TXN_9226047    1\n",
      "TXN_8567525    1\n",
      "TXN_4583012    1\n",
      "TXN_6796890    1\n",
      "TXN_9933628    1\n",
      "              ..\n",
      "TXN_3160411    1\n",
      "TXN_7034554    1\n",
      "TXN_4271903    1\n",
      "TXN_4977031    1\n",
      "TXN_1961373    1\n",
      "Name: count, Length: 10000, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: item\n",
      "Value Counts:\n",
      "item\n",
      "Coffee               1284\n",
      "Salad                1270\n",
      "Cookie               1209\n",
      "Tea                  1199\n",
      "Juice                1171\n",
      "Cake                 1139\n",
      "Sandwich             1131\n",
      "Smoothie             1096\n",
      "Cake/Juice            234\n",
      "Smoothie/Sandwich     213\n",
      "NaN                    54\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: quantity\n",
      "Value Counts:\n",
      "quantity\n",
      "5      2013\n",
      "2      1974\n",
      "4      1863\n",
      "3      1849\n",
      "1      1822\n",
      "NaN     479\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: price_per_unit\n",
      "Value Counts:\n",
      "price_per_unit\n",
      "3.0    2429\n",
      "4.0    2331\n",
      "2.0    1227\n",
      "5.0    1204\n",
      "1.0    1143\n",
      "1.5    1133\n",
      "NaN     533\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: total_spent\n",
      "Value Counts:\n",
      "total_spent\n",
      "6.0     979\n",
      "12.0    939\n",
      "3.0     930\n",
      "4.0     923\n",
      "20.0    746\n",
      "15.0    734\n",
      "8.0     677\n",
      "10.0    524\n",
      "NaN     502\n",
      "2.0     497\n",
      "9.0     479\n",
      "5.0     468\n",
      "16.0    444\n",
      "25.0    259\n",
      "7.5     237\n",
      "1.0     232\n",
      "4.5     225\n",
      "1.5     205\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: payment_method\n",
      "Value Counts:\n",
      "payment_method\n",
      "NaN               3178\n",
      "Digital Wallet    2291\n",
      "Credit Card       2273\n",
      "Cash              2258\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: location\n",
      "Value Counts:\n",
      "location\n",
      "NaN         3961\n",
      "Takeaway    3022\n",
      "In-store    3017\n",
      "Name: count, dtype: int64\n",
      "------------------------------\n",
      "\n",
      " Column: transaction_date\n",
      "Value Counts:\n",
      "transaction_date\n",
      "NaN           460\n",
      "2023-06-16     40\n",
      "2023-02-06     40\n",
      "2023-09-21     39\n",
      "2023-07-21     39\n",
      "             ... \n",
      "2023-11-24     15\n",
      "2023-04-27     15\n",
      "2023-07-22     14\n",
      "2023-02-17     14\n",
      "2023-03-11     14\n",
      "Name: count, Length: 366, dtype: int64\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, we want to investigate data quality issues for each column.\n",
    "# So, we check for each column the unique values and their counts including NaNs.\n",
    "# Loop through every single column in the dataframe\n",
    "# then we read the results to try catch anything unusual.\n",
    "for col in df.columns:\n",
    "    print(f\" Column: {col}\")\n",
    "    \n",
    "    # Show Value Counts including NaNs \n",
    "    print(\"Value Counts:\")\n",
    "    print(df[col].value_counts(dropna=False))\n",
    "    # This is just separator for readibility\n",
    "    print(\"-\" * 30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa462c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the value counts above, we can see that there are several columns that have \"ERROR\", \"UNKNOWN\" and nan values.\n",
    "# We will standardize these values to be nan for easier handling.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define your mapping rules\n",
    "rules = {\n",
    "    'ERROR': np.nan,\n",
    "    'UNKNOWN': np.nan\n",
    "}\n",
    "\n",
    "# Apply to the entire DataFrame\n",
    "df = df.replace(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c2e97",
   "metadata": {},
   "source": [
    "FILLNA FOR ITEM COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fcdff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17      3.0\n",
       "19      3.0\n",
       "27      3.0\n",
       "43      3.0\n",
       "46      3.0\n",
       "       ... \n",
       "9960    3.0\n",
       "9967    3.0\n",
       "9977    3.0\n",
       "9987    3.0\n",
       "9989    3.0\n",
       "Name: price_per_unit, Length: 1171, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we take a look at all rows where item is \"Juice\", the value for price_per_unit is always 3.0.\n",
    "df[df['item'] == \"Juice\"]['price_per_unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next,if we take a look at all rows where item is \"Coffee\", the value for price_per_unit is always 2.0.\n",
    "# We can see there is consistency in value of price_per_unit for different items\n",
    "# Meaning we can impute missing or unknown items based on the price per unit.\n",
    "df[df['item'] == \"Coffee\"]['price_per_unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b93d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1.0': 'Cookie', '1.5': 'Tea', '2.0': 'Coffee', '3.0': 'Cake/Juice', '4.0': 'Smoothie/Sandwich', '5.0': 'Salad'}\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary from price_per_unit to item\n",
    "price_grouping = (\n",
    "    df[df['item'].notna()]  #  filter out NaN values, we only want to map known items.\n",
    "    .groupby('price_per_unit')['item'] # group by price_per_unit and get the item values. e.g price_per_unit = 2.0 -> [\"Coffee\", \"Coffee\", ...]\n",
    "    .unique() # makes sure each item is only listed once per price bucket. You don't want a dictionary that says 1.0: \"Cookie, Cookie, Cookie...\"\n",
    "    .apply(lambda x: \"/\".join(map(str, x))) # some prices might map to multiple items, so we join them with a slash. e.g 3.0: \"Cake/Juice\"\n",
    "    .to_dict() # convert to dictionary for mapping  \n",
    ")\n",
    "\n",
    "print(price_grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before using the mapping, ensure the price_per_unit column is numeric float, as it might have been read as object/string type.\n",
    "import pandas as pd\n",
    "\n",
    "df['price_per_unit'] = pd.to_numeric(df['price_per_unit'], errors='coerce')\n",
    "\n",
    "# Price_per_unit is float, but we also need to make sure the keys in the mapping dictionary 'price_grouping' are also float.\n",
    "# So we convert them.\n",
    "clean_mapping = {float(k): v for k, v in price_grouping.items()}\n",
    "\n",
    "# Now we can use this mapping to fill in the missing item values.\n",
    "df['item'] = df['item'].fillna(df['price_per_unit'].map(clean_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360396ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item is Nan X price_per_unit notNan count: 0\n"
     ]
    }
   ],
   "source": [
    "# Let's verify our fillna, we have two conditions : item is naN AND price_per_unit is NOT NaN. filter this should give us 0 rows.\n",
    "# We should still have Nan for item if price_per_unit is also NaN.\n",
    "missing = df['item'].isna() & df['price_per_unit'].notna()\n",
    "\n",
    "print(f\"Item is Nan X price_per_unit notNan count: {missing.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e93b1",
   "metadata": {},
   "source": [
    "FILLNA FOR QUANTITY, PRICE PER UNIT, TOTAL SPENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f533b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next,for 3 columns, quantity, price_per_unit, total_price is connected via a formula:\n",
    "# total_price = quantity * price_per_unit\n",
    "# So we can use this formula to impute missing values in any of these 3 columns\n",
    "# We will create a function on condition that only one of the 3 columns is missing, we can calculate it from the other two.\n",
    "# If more than one is missing, we cannot impute it.\n",
    "\n",
    "# Define the columns we are working with\n",
    "# Purposely using col2 to avoid confusion with col defined earlier\n",
    "col2 = ['quantity', 'price_per_unit', 'total_spent']\n",
    "\n",
    "# Convert string columns to float, or else it unsolvable\n",
    "# errors='coerce' turns non-numeric strings into NaN so they can be solved\n",
    "for c in col2:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Create a mask for rows where exactly ONE value is missing\n",
    "mask_one_missing = df[col2].isnull().sum(axis=1) == 1\n",
    "\n",
    "\n",
    "# Calculate Missing 'total_spent'\n",
    "df.loc[mask_one_missing & df['total_spent'].isnull(), # filter rows with one missing and total_spent is missing\n",
    "    'total_spent'] = df['quantity'] * df['price_per_unit'] # then use formula\n",
    "\n",
    "#  Calculate Missing 'quantity'\n",
    "df.loc[mask_one_missing & df['quantity'].isnull(), 'quantity'] = \\\n",
    "    df['total_spent'] / df['price_per_unit']\n",
    "\n",
    "# Calculate Missing 'price_per_unit'\n",
    "df.loc[mask_one_missing & df['price_per_unit'].isnull(), 'price_per_unit'] = \\\n",
    "    df['total_spent'] / df['quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b20a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with exactly one missing value among ['quantity', 'price_per_unit', 'total_spent']: 0\n"
     ]
    }
   ],
   "source": [
    "# Lets verify this\n",
    "# 'col2' and 'mask_one_missing' are already defined above\n",
    "# This should produce 0\n",
    "\n",
    "print(f\"Rows with exactly one missing value among {col2}: {mask_one_missing.sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
